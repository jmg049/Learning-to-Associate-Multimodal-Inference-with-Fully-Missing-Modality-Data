\subsection{C-MAM Reconstruction Error Metrics}
\Cref{tab:errors} presents the error metrics, MAE and MSE, of the generated features. Interestingly, high error values did not always correlate with poor performance recovery. For example, despite high error metrics for the Kinetics-Sounds audio-to-video model, C-MAMs improved performance by 20\%-25\%. This suggests that some multimodal models are resilient to noisy inputs, further validating the practical utility of C-MAMs.

\input{sections/ablations/mae_mse}

Even with elevated error metrics in certain cases, C-MAMs consistently improved performance, demonstrating their ability to recover meaningful features despite imperfect reconstructions. This indicates that latent spaces in multimodal models can be resilient to noisy or incomplete inputs, reinforcing the practical applicability of C-MAMs in real-world scenarios.

\subsection{T-SNE Visualisations}
illustrates t-SNE visualizations comparing embeddings generated by C-MAMs to the ground truth. While t-SNE visualizations have limitations, they show that in many cases, such as for AVMNIST and MM-IMDb, C-MAMs produce embeddings close to the original modality features. These visualizations support the conclusion that C-MAMs effectively reconstruct missing features and maintain model performance in practical applications.

\subsection{Bi-Modal C-MAM Contributions}
\Cref{tab:contributions} presents performance metrics for the bimodal C-MAMs used in experiment three, specifically when one modality is entirely absent. For the EMT-DLFR models trained on the MOSI dataset, we observe a similar drop in performance metrics regardless of which modality is missing. We also observe that for both datasets and models that an individual modality is capable of producing nearly identical Has0 Accuracy scores to the C-MAM with both modalities. This is also observed for the Has0 F1-Score for the robust model trained on MOSI when audio is missing. The baseline F1-Score decreases by approximately 3\%. For the MOSEI dataset, while the accuracy is not impacted by a missing modality, the F1-Score is. For both models, there is a significant decrease in the F1-Score.

In the MMIN experiment's baseline model, where both audio and video are used to generate text, the bimodal C-MAMs exhibit similar performance decreases irrespective of the missing modality. This again implies that the C-MAM leverages information equally from each modality. However, when the text modality is utilized, a larger performance decrease is observed, which is expected since the best-performing conditions include the text modality, which is recognised in many studies as a powerful information source. Despite this bias towards text, there remains a significant performance drop when either audio or video is missing, indicating that the C-MAMs effectively utilize information from these modalities as well.
\input{tables/contributions}